{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "from src.models.transcription import TranscriptionService\n",
    "from src.models.diarization import SpeakerDiarizationService\n",
    "from src.processing.transcript_processor import TranscriptProcessor\n",
    "\n",
    "# Initialize services\n",
    "transcription_service = TranscriptionService()\n",
    "diarization_service = SpeakerDiarizationService()\n",
    "processor = TranscriptProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = \"../../data/test_data/long_conversation.mp3\"\n",
    "sample = \"../../data/test_data/bel.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/audio-analyzer/src/models/transcription.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sr = librosa.load(audio_path, sr=16000)\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[{'timestamp': (0.0, 2.32), 'text': ' Там в Америке меня не хватает.', 'speaker': 'SPEAKER_00'}, {'timestamp': (3.3200000000000003, 11.540000000000001), 'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'speaker': 'SPEAKER_00'}, {'timestamp': (11.9, 16.14), 'text': ' Вам надо сегодня в США остыть, успокоиться.', 'speaker': 'SPEAKER_00'}]\n"
     ]
    }
   ],
   "source": [
    "sample_transcription = transcription_service.transcribe_with_chunks(sample)\n",
    "print(len(sample_transcription))\n",
    "sample_diarization = diarization_service.diarize(sample)\n",
    "print(len(sample_diarization))\n",
    "sample_transcript = processor.merge_transcription_with_speakers(sample_transcription, sample_diarization)\n",
    "\n",
    "# Display results\n",
    "print(sample_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Там в Америке меня не хватает.', 'timestamp': (0.0, 2.32)}\n",
      "{'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'timestamp': (3.3200000000000003, 11.540000000000001)}\n",
      "{'text': ' Вам надо сегодня в США остыть, успокоиться.', 'timestamp': (11.9, 16.14)}\n"
     ]
    }
   ],
   "source": [
    "for some in sample_transcription:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0.28409375000000003, 'end': 2.32596875, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 3.27096875, 'end': 5.228468750000001, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 6.37596875, 'end': 13.98659375, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 15.31971875, 'end': 16.26471875, 'speaker': 'SPEAKER_00'}\n"
     ]
    }
   ],
   "source": [
    "for some in sample_diarization:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPEAKER_00 [0.00s - 2.32s]: Там в Америке меня не хватает.\\nSPEAKER_00 [3.32s - 11.54s]: Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.\\nSPEAKER_00 [11.90s - 16.14s]: Вам надо сегодня в США остыть, успокоиться.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.format_transcript_for_display(sample_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 10:01:35,859 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4640a1a3fece44b9a72f5ed290468f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-09 10:01:38,112 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-09 10:01:38,112 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: Short transcript processed as single topic. Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/umap/spectral.py:519: RuntimeWarning:\n",
      "\n",
      "k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/umap/spectral.py:519: RuntimeWarning:\n",
      "\n",
      "k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.clustering.semantic_cluster import SemanticCluster\n",
    "\n",
    "cluster_service = SemanticCluster()\n",
    "\n",
    "clusters = cluster_service.fit_transform(\n",
    "    sample_transcript\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 2.32), 'text': ' Там в Америке меня не хватает.', 'speaker': 'SPEAKER_00'}, {'timestamp': (3.3200000000000003, 11.540000000000001), 'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'speaker': 'SPEAKER_00'}, {'timestamp': (11.9, 16.14), 'text': ' Вам надо сегодня в США остыть, успокоиться.', 'speaker': 'SPEAKER_00'}]\n"
     ]
    }
   ],
   "source": [
    "for some in clusters:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPEAKER_00 [00:00:00.00-00:00:02.32]: Там в Америке меня не хватает.\\nSPEAKER_00 [00:00:03.32-00:00:11.54]: Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.\\nSPEAKER_00 [00:00:11.90-00:00:16.14]: Вам надо сегодня в США остыть, успокоиться.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_clusters = processor.format_transcript_by_topic(clusters)\n",
    "formatted_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.summarization import SummarizationService\n",
    "\n",
    "summarization_service = SummarizationService()\n",
    "summaries = summarization_service.summarize_all_topics(formatted_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Summary\n",
      "The speaker expresses concern about a situation in America, suggesting they would directly confront President Trump on certain actions that are unacceptable. They also advise the person to calm down and cool off in the United States.\n",
      "\n",
      "## Notable Moments\n",
      "- 00:02:32 Quote: \"Там в Америке меня не хватает.\" - [Brief context of speaker's concern about America]\n",
      "- 00:11:54 Quote: \"Вынад сегодня в США остыть, успокоиться.\" - [Speaker advising to calm down and cool off in the US]\n"
     ]
    }
   ],
   "source": [
    "for summary in summaries:\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
