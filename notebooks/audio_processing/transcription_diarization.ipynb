{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "Device set to use cuda\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "from src.models.transcription import TranscriptionService\n",
    "from src.models.diarization import SpeakerDiarizationService\n",
    "from src.processing.transcript_processor import TranscriptProcessor\n",
    "\n",
    "# Initialize services\n",
    "transcription_service = TranscriptionService()\n",
    "diarization_service = SpeakerDiarizationService()\n",
    "processor = TranscriptProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = \"../../data/test_data/long_conversation.mp3\"\n",
    "sample = \"../../data/test_data/bel.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/audio-analyzer/src/models/transcription.py:88: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio_data, sr = librosa.load(audio_path, sr=16000)\n",
      "/opt/conda/lib/python3.10/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[{'timestamp': (0.0, 2.32), 'text': ' Там в Америке меня не хватает.', 'speaker': 'SPEAKER_00'}, {'timestamp': (3.3200000000000003, 11.540000000000001), 'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'speaker': 'SPEAKER_00'}, {'timestamp': (11.9, 16.14), 'text': ' Вам надо сегодня в США остыть, успокоиться.', 'speaker': 'SPEAKER_00'}]\n"
     ]
    }
   ],
   "source": [
    "sample_transcription = transcription_service.transcribe_with_chunks(sample)\n",
    "print(len(sample_transcription))\n",
    "sample_diarization = diarization_service.diarize(sample)\n",
    "print(len(sample_diarization))\n",
    "sample_transcript = processor.merge_transcription_with_speakers(sample_transcription, sample_diarization)\n",
    "\n",
    "# Display results\n",
    "print(sample_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' Там в Америке меня не хватает.', 'timestamp': (0.0, 2.32)}\n",
      "{'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'timestamp': (3.3200000000000003, 11.540000000000001)}\n",
      "{'text': ' Вам надо сегодня в США остыть, успокоиться.', 'timestamp': (11.9, 16.14)}\n"
     ]
    }
   ],
   "source": [
    "for some in sample_transcription:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start': 0.28409375000000003, 'end': 2.32596875, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 3.27096875, 'end': 5.228468750000001, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 6.37596875, 'end': 13.98659375, 'speaker': 'SPEAKER_00'}\n",
      "{'start': 15.31971875, 'end': 16.26471875, 'speaker': 'SPEAKER_00'}\n"
     ]
    }
   ],
   "source": [
    "for some in sample_diarization:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SPEAKER_00 [0.00s - 2.32s]: Там в Америке меня не хватает.\\nSPEAKER_00 [3.32s - 11.54s]: Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.\\nSPEAKER_00 [11.90s - 16.14s]: Вам надо сегодня в США остыть, успокоиться.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.format_transcript_for_display(sample_transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:datasets:PyTorch version 2.6.0 available.\n",
      "2025-03-08 17:53:15,160 - BERTopic - Embedding - Transforming documents to embeddings.\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c9e1fb419e49dc8114d053a648a751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 17:53:17,345 - BERTopic - Embedding - Completed ✓\n",
      "2025-03-08 17:53:17,346 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice: Short transcript processed as single topic. Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/umap/spectral.py:519: RuntimeWarning:\n",
      "\n",
      "k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "\n",
      "/opt/conda/lib/python3.10/site-packages/umap/spectral.py:519: RuntimeWarning:\n",
      "\n",
      "k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.clustering.semantic_cluster import SemanticCluster\n",
    "\n",
    "cluster_service = SemanticCluster()\n",
    "\n",
    "clusters = cluster_service.fit_transform(\n",
    "    sample_transcript\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'timestamp': (0.0, 2.32), 'text': ' Там в Америке меня не хватает.', 'speaker': 'SPEAKER_00'}, {'timestamp': (3.3200000000000003, 11.540000000000001), 'text': ' Вот я бы Трампу прямо в глаза сказал, что нельзя, не что даже, а как нельзя делать.', 'speaker': 'SPEAKER_00'}, {'timestamp': (11.9, 16.14), 'text': ' Вам надо сегодня в США остыть, успокоиться.', 'speaker': 'SPEAKER_00'}]\n"
     ]
    }
   ],
   "source": [
    "for some in clusters:\n",
    "    print(some)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
